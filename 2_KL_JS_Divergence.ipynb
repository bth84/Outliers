{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurements of Distance between distributions\n",
    "\n",
    "## The questions\n",
    "\n",
    "1. We have a master distribution, e.g. of values that occured on a stationary timeseries throughout the last two years on a daily base. We get a new timeseries for the recently past quarter.<br>**How similar is the distribution of new values in comparison to those of the past?**\n",
    "<br>**Are the amount and quality of outliers suspicious?**\n",
    "\n",
    "2. We know, that the _shapes_ of certain timeseries (e.g. imports) are very similar to each other. We get the current update on those.<br>**Is there any \"outlier\" regarding the amount of occurences of values?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"The\" Answer: Kullback-Leibler-Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Wikipedia](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence):\n",
    "> Is a measure of how one probability distribution is different from a second, reference probability distribution.\n",
    "\n",
    "Perfect similarity between two different PDFs imply a KL Divergence of 0. The more dissimilarity between both, the higher the value. Can also be used to measure the randomness of a timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import rel_entr\n",
    "\n",
    "def plot(p,q):\n",
    "    plt.plot(x, p)\n",
    "    plt.plot(x, q)\n",
    "    plt.fill_between(x, p, q, where=q>=p, interpolate=True)\n",
    "    plt.fill_between(x, p, q, where=q<=p, interpolate=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(0, 20, 0.001)\n",
    "\n",
    "p = stats.norm.pdf(x,10,2)\n",
    "q = stats.norm.pdf(x,11,2)\n",
    "\n",
    "plot(p,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = p/p.sum()\n",
    "q = q/q.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rel_entr(p, q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's diverge the shapes a little bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = stats.norm.pdf(x,13,5)\n",
    "q = q / q.sum()\n",
    "\n",
    "plot(p,q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe KL-Divergence to raise to sill a low value, since the shapes are still similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rel_entr(p, q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about exponential distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = stats.expon.pdf(x)\n",
    "q = q/q.sum()\n",
    "plot(p,q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the divergence raises significantly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rel_entr(p, q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL Divergence is not symmetrical!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rel_entr(p, q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rel_entr(q, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A symmetrical extension: Jennsen-Shannon-Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import jensenshannon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jensenshannon(p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jensenshannon(p, q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
